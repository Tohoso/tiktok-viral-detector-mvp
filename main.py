#!/usr/bin/env python3
"""
TikTok Viral Video Detector MVP
TikAPIã‚’ä½¿ç”¨ã—ã¦For You Pageã‹ã‚‰24æ™‚é–“ä»¥å†…50ä¸‡å†ç”Ÿå‹•ç”»ã‚’æ¤œå‡º

Author: Manus AI
Version: 1.0.0
Date: 2025-08-02
"""

import requests
import json
import time
import csv
import os
import sys
from datetime import datetime, timedelta
from typing import List, Dict, Optional
import logging

# Google Sheetsé€£æºç”¨
try:
    import gspread
    from google.oauth2.service_account import Credentials
    GOOGLE_SHEETS_AVAILABLE = True
except ImportError:
    GOOGLE_SHEETS_AVAILABLE = False
    print("âš ï¸ Google Sheetsé€£æºãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã€‚pip install gspread google-auth ã§ã‚¤ãƒ³ã‚¹ãƒˆãƒ¼ãƒ«ã—ã¦ãã ã•ã„ã€‚")

class TikAPIClient:
    """TikAPI ã‚¯ãƒ©ã‚¤ã‚¢ãƒ³ãƒˆ"""
    
    def __init__(self, api_key: str):
        self.api_key = api_key
        self.base_url = "https://tikapi.io/api/v1"
        self.session = requests.Session()
        self.session.headers.update({
            "X-API-KEY": api_key,
            "Content-Type": "application/json"
        })
        
        # ãƒ¬ãƒ¼ãƒˆåˆ¶é™å¯¾å¿œ
        self.last_request_time = 0
        self.min_request_interval = 1.0  # 1ç§’é–“éš”
    
    def _wait_for_rate_limit(self):
        """ãƒ¬ãƒ¼ãƒˆåˆ¶é™ã‚’è€ƒæ…®ã—ãŸå¾…æ©Ÿ"""
        current_time = time.time()
        time_since_last = current_time - self.last_request_time
        
        if time_since_last < self.min_request_interval:
            wait_time = self.min_request_interval - time_since_last
            time.sleep(wait_time)
        
        self.last_request_time = time.time()
    
    def get_fyp_videos(self, count: int = 30, country: str = "us") -> Dict:
        """For You Pageå‹•ç”»ã‚’å–å¾—"""
        self._wait_for_rate_limit()
        
        url = f"{self.base_url}/public/explore"
        params = {
            "count": min(count, 30),  # TikAPIã®åˆ¶é™
            "country": country
        }
        
        try:
            response = self.session.get(url, params=params, timeout=30)
            response.raise_for_status()
            return response.json()
        
        except requests.exceptions.RequestException as e:
            logging.error(f"TikAPI ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return {"itemList": [], "hasMore": False}
    
    def get_trending_videos(self, count: int = 30, country: str = "us") -> Dict:
        """ãƒˆãƒ¬ãƒ³ãƒ‰å‹•ç”»ã‚’å–å¾—ï¼ˆFYPã®ä»£æ›¿ï¼‰"""
        self._wait_for_rate_limit()
        
        url = f"{self.base_url}/public/trending"
        params = {
            "count": min(count, 30),
            "country": country
        }
        
        try:
            response = self.session.get(url, params=params, timeout=30)
            response.raise_for_status()
            return response.json()
        
        except requests.exceptions.RequestException as e:
            logging.error(f"TikAPI ãƒˆãƒ¬ãƒ³ãƒ‰ãƒªã‚¯ã‚¨ã‚¹ãƒˆã‚¨ãƒ©ãƒ¼: {e}")
            return {"itemList": [], "hasMore": False}

class ViralVideoDetector:
    """ãƒã‚¤ãƒ©ãƒ«å‹•ç”»æ¤œå‡ºå™¨"""
    
    def __init__(self, min_views: int = 500000, time_limit_hours: int = 24):
        self.min_views = min_views
        self.time_limit_hours = time_limit_hours
    
    def is_viral_video(self, video: Dict) -> bool:
        """å‹•ç”»ãŒãƒã‚¤ãƒ©ãƒ«æ¡ä»¶ã‚’æº€ãŸã™ã‹ãƒã‚§ãƒƒã‚¯"""
        try:
            # æŠ•ç¨¿æ™‚åˆ»ã®å–å¾—
            create_time = self._parse_create_time(video)
            if not create_time:
                return False
            
            # 24æ™‚é–“ä»¥å†…ãƒã‚§ãƒƒã‚¯
            time_diff = datetime.now() - create_time
            if time_diff > timedelta(hours=self.time_limit_hours):
                return False
            
            # å†ç”Ÿæ•°ãƒã‚§ãƒƒã‚¯
            views = self._extract_view_count(video)
            return views >= self.min_views
            
        except Exception as e:
            logging.warning(f"ãƒã‚¤ãƒ©ãƒ«åˆ¤å®šã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _parse_create_time(self, video: Dict) -> Optional[datetime]:
        """æŠ•ç¨¿æ™‚åˆ»ã‚’è§£æ"""
        try:
            # TikAPIã®å ´åˆ
            if 'createTime' in video:
                timestamp = video['createTime']
                if isinstance(timestamp, str):
                    timestamp = int(timestamp)
                return datetime.fromtimestamp(timestamp)
            
            # ä»–ã®å½¢å¼ã®å ´åˆ
            if 'create_time' in video:
                return datetime.fromtimestamp(video['create_time'])
            
            return None
            
        except (ValueError, TypeError) as e:
            logging.warning(f"æ™‚åˆ»è§£æã‚¨ãƒ©ãƒ¼: {e}")
            return None
    
    def _extract_view_count(self, video: Dict) -> int:
        """å†ç”Ÿæ•°ã‚’æŠ½å‡º"""
        try:
            # TikAPIã®å ´åˆ
            if 'stats' in video and 'playCount' in video['stats']:
                return int(video['stats']['playCount'])
            
            # ç›´æ¥æŒ‡å®šã®å ´åˆ
            if 'playCount' in video:
                return int(video['playCount'])
            
            if 'view_count' in video:
                return int(video['view_count'])
            
            return 0
            
        except (ValueError, TypeError):
            return 0
    
    def extract_video_info(self, video: Dict) -> Dict:
        """å‹•ç”»æƒ…å ±ã‚’æŠ½å‡ºãƒ»æ•´å½¢"""
        create_time = self._parse_create_time(video)
        views = self._extract_view_count(video)
        
        # çµŒéæ™‚é–“è¨ˆç®—
        hours_since_post = 0
        if create_time:
            time_diff = datetime.now() - create_time
            hours_since_post = round(time_diff.total_seconds() / 3600, 1)
        
        # ãƒã‚¤ãƒ©ãƒ«é€Ÿåº¦è¨ˆç®—
        viral_speed = 0
        if hours_since_post > 0:
            viral_speed = round(views / hours_since_post, 0)
        
        # å‹•ç”»URLç”Ÿæˆ
        video_id = video.get('id', '')
        author_username = video.get('author', {}).get('uniqueId', '')
        video_url = f"https://www.tiktok.com/@{author_username}/video/{video_id}" if video_id and author_username else ""
        
        return {
            'video_id': video_id,
            'description': video.get('desc', '')[:100] + ('...' if len(video.get('desc', '')) > 100 else ''),
            'views': views,
            'likes': video.get('stats', {}).get('likeCount', 0),
            'comments': video.get('stats', {}).get('commentCount', 0),
            'shares': video.get('stats', {}).get('shareCount', 0),
            'author_username': author_username,
            'author_follower_count': video.get('author', {}).get('followerCount', 0),
            'create_time': create_time.strftime('%Y-%m-%d %H:%M:%S') if create_time else '',
            'hours_since_post': hours_since_post,
            'viral_speed': viral_speed,
            'video_url': video_url,
            'hashtags': ', '.join([tag.get('title', '') for tag in video.get('textExtra', []) if tag.get('hashtagName')]),
            'is_verified': video.get('author', {}).get('verified', False)
        }

class GoogleSheetsExporter:
    """Google Sheetså‡ºåŠ›ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, credentials_path: str = "credentials.json"):
        self.credentials_path = credentials_path
        self.gc = None
        self._initialize()
    
    def _initialize(self):
        """Google Sheets APIåˆæœŸåŒ–"""
        if not GOOGLE_SHEETS_AVAILABLE:
            return
        
        try:
            if os.path.exists(self.credentials_path):
                scope = [
                    'https://www.googleapis.com/auth/spreadsheets',
                    'https://www.googleapis.com/auth/drive'
                ]
                creds = Credentials.from_service_account_file(self.credentials_path, scopes=scope)
                self.gc = gspread.authorize(creds)
                logging.info("Google Sheets APIåˆæœŸåŒ–æˆåŠŸ")
            else:
                logging.warning(f"èªè¨¼ãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.credentials_path}")
        
        except Exception as e:
            logging.error(f"Google Sheets APIåˆæœŸåŒ–ã‚¨ãƒ©ãƒ¼: {e}")
    
    def export_to_sheets(self, viral_videos: List[Dict], spreadsheet_id: str = None, sheet_name: str = None) -> bool:
        """Google Sheetsã«å‡ºåŠ›"""
        if not self.gc:
            logging.error("Google Sheets APIãŒåˆæœŸåŒ–ã•ã‚Œã¦ã„ã¾ã›ã‚“")
            return False
        
        try:
            # ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆå–å¾—ã¾ãŸã¯ä½œæˆ
            if spreadsheet_id:
                spreadsheet = self.gc.open_by_key(spreadsheet_id)
            else:
                spreadsheet_name = f"TikTok Viral Videos {datetime.now().strftime('%Y%m%d_%H%M%S')}"
                spreadsheet = self.gc.create(spreadsheet_name)
                logging.info(f"æ–°ã—ã„ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’ä½œæˆ: {spreadsheet_name}")
            
            # ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆå–å¾—ã¾ãŸã¯ä½œæˆ
            if not sheet_name:
                sheet_name = f"Viral_{datetime.now().strftime('%m%d_%H%M')}"
            
            try:
                worksheet = spreadsheet.worksheet(sheet_name)
                worksheet.clear()  # æ—¢å­˜ãƒ‡ãƒ¼ã‚¿ã‚’ã‚¯ãƒªã‚¢
            except gspread.WorksheetNotFound:
                worksheet = spreadsheet.add_worksheet(title=sheet_name, rows=1000, cols=20)
            
            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œ
            headers = [
                'å‹•ç”»ID', 'èª¬æ˜', 'å†ç”Ÿæ•°', 'ã„ã„ã­æ•°', 'ã‚³ãƒ¡ãƒ³ãƒˆæ•°', 'ã‚·ã‚§ã‚¢æ•°',
                'ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå', 'ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°', 'æŠ•ç¨¿æ—¥æ™‚', 'çµŒéæ™‚é–“(h)', 
                'ãƒã‚¤ãƒ©ãƒ«é€Ÿåº¦', 'å‹•ç”»URL', 'ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°', 'èªè¨¼æ¸ˆã¿'
            ]
            
            # ãƒ‡ãƒ¼ã‚¿æº–å‚™
            data = [headers]
            for video in viral_videos:
                row = [
                    video['video_id'],
                    video['description'],
                    video['views'],
                    video['likes'],
                    video['comments'],
                    video['shares'],
                    video['author_username'],
                    video['author_follower_count'],
                    video['create_time'],
                    video['hours_since_post'],
                    video['viral_speed'],
                    video['video_url'],
                    video['hashtags'],
                    'âœ“' if video['is_verified'] else ''
                ]
                data.append(row)
            
            # ä¸€æ‹¬æ›´æ–°
            worksheet.update('A1', data)
            
            # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè¨­å®š
            self._format_worksheet(worksheet, len(viral_videos))
            
            logging.info(f"Google Sheetsã«{len(viral_videos)}ä»¶ã®ãƒ‡ãƒ¼ã‚¿ã‚’å‡ºåŠ›ã—ã¾ã—ãŸ")
            logging.info(f"ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆURL: {spreadsheet.url}")
            
            return True
            
        except Exception as e:
            logging.error(f"Google Sheetså‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def _format_worksheet(self, worksheet, data_rows: int):
        """ãƒ¯ãƒ¼ã‚¯ã‚·ãƒ¼ãƒˆã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè¨­å®š"""
        try:
            # ãƒ˜ãƒƒãƒ€ãƒ¼è¡Œã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            worksheet.format('A1:N1', {
                'backgroundColor': {'red': 0.2, 'green': 0.6, 'blue': 1.0},
                'textFormat': {'bold': True, 'foregroundColor': {'red': 1, 'green': 1, 'blue': 1}},
                'horizontalAlignment': 'CENTER'
            })
            
            # æ•°å€¤åˆ—ã®ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            if data_rows > 0:
                # å†ç”Ÿæ•°ã€ã„ã„ã­æ•°ã€ã‚³ãƒ¡ãƒ³ãƒˆæ•°ã€ã‚·ã‚§ã‚¢æ•°
                worksheet.format(f'C2:F{data_rows + 1}', {'numberFormat': {'type': 'NUMBER', 'pattern': '#,##0'}})
                
                # ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°
                worksheet.format(f'H2:H{data_rows + 1}', {'numberFormat': {'type': 'NUMBER', 'pattern': '#,##0'}})
                
                # ãƒã‚¤ãƒ©ãƒ«é€Ÿåº¦
                worksheet.format(f'K2:K{data_rows + 1}', {'numberFormat': {'type': 'NUMBER', 'pattern': '#,##0'}})
            
            # åˆ—å¹…èª¿æ•´
            worksheet.columns_auto_resize(0, 13)
            
        except Exception as e:
            logging.warning(f"ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆè¨­å®šã‚¨ãƒ©ãƒ¼: {e}")

class TikTokViralMVP:
    """TikTok ãƒã‚¤ãƒ©ãƒ«å‹•ç”»æ¤œå‡º MVP"""
    
    def __init__(self, config_path: str = "config.json"):
        self.config = self._load_config(config_path)
        self.tikapi = TikAPIClient(self.config['tikapi_key'])
        self.detector = ViralVideoDetector(
            min_views=self.config.get('min_views', 500000),
            time_limit_hours=self.config.get('time_limit_hours', 24)
        )
        self.sheets_exporter = GoogleSheetsExporter(self.config.get('credentials_path', 'credentials.json'))
        
        # ãƒ­ã‚°è¨­å®š
        logging.basicConfig(
            level=logging.INFO,
            format='%(asctime)s - %(levelname)s - %(message)s',
            handlers=[
                logging.FileHandler('tiktok_viral_mvp.log'),
                logging.StreamHandler()
            ]
        )
    
    def _load_config(self, config_path: str) -> Dict:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿"""
        if os.path.exists(config_path):
            try:
                with open(config_path, 'r', encoding='utf-8') as f:
                    return json.load(f)
            except Exception as e:
                logging.error(f"è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
        
        # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
        return {
            'tikapi_key': 'YOUR_TIKAPI_KEY_HERE',
            'min_views': 500000,
            'time_limit_hours': 24,
            'max_requests': 10,
            'countries': ['us', 'jp'],
            'spreadsheet_id': '',
            'credentials_path': 'credentials.json'
        }
    
    def create_sample_config(self):
        """ã‚µãƒ³ãƒ—ãƒ«è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ"""
        config = {
            "tikapi_key": "YOUR_TIKAPI_KEY_HERE",
            "min_views": 500000,
            "time_limit_hours": 24,
            "max_requests": 10,
            "countries": ["us", "jp"],
            "spreadsheet_id": "YOUR_SPREADSHEET_ID_HERE",
            "credentials_path": "credentials.json",
            "output_csv": True,
            "csv_filename": "viral_videos_{timestamp}.csv"
        }
        
        with open('config.json', 'w', encoding='utf-8') as f:
            json.dump(config, f, indent=2, ensure_ascii=False)
        
        print("âœ… ã‚µãƒ³ãƒ—ãƒ«è¨­å®šãƒ•ã‚¡ã‚¤ãƒ« config.json ã‚’ä½œæˆã—ã¾ã—ãŸ")
        print("ğŸ“ TikAPIã‚­ãƒ¼ã¨Google Sheetsã®è¨­å®šã‚’ç·¨é›†ã—ã¦ãã ã•ã„")
    
    async def collect_viral_videos(self) -> List[Dict]:
        """ãƒã‚¤ãƒ©ãƒ«å‹•ç”»ã‚’åé›†"""
        all_viral_videos = []
        total_processed = 0
        
        logging.info("ğŸš€ TikTok ãƒã‚¤ãƒ©ãƒ«å‹•ç”»æ¤œå‡ºã‚’é–‹å§‹ã—ã¾ã™")
        logging.info(f"ğŸ“Š æ¡ä»¶: {self.config['time_limit_hours']}æ™‚é–“ä»¥å†…ã«{self.config['min_views']:,}å†ç”Ÿä»¥ä¸Š")
        
        countries = self.config.get('countries', ['us'])
        max_requests = self.config.get('max_requests', 10)
        
        for country in countries:
            logging.info(f"ğŸŒ {country.upper()} åœ°åŸŸã®å‹•ç”»ã‚’æ¤œç´¢ä¸­...")
            
            for request_num in range(max_requests):
                try:
                    # FYPå‹•ç”»ã‚’å–å¾—
                    fyp_response = self.tikapi.get_fyp_videos(count=30, country=country)
                    fyp_videos = fyp_response.get('itemList', [])
                    
                    # ãƒˆãƒ¬ãƒ³ãƒ‰å‹•ç”»ã‚‚å–å¾—ï¼ˆè£œå®Œï¼‰
                    trending_response = self.tikapi.get_trending_videos(count=30, country=country)
                    trending_videos = trending_response.get('itemList', [])
                    
                    # å‹•ç”»ã‚’ãƒãƒ¼ã‚¸ï¼ˆé‡è¤‡é™¤å»ï¼‰
                    all_videos = self._merge_videos(fyp_videos, trending_videos)
                    total_processed += len(all_videos)
                    
                    # ãƒã‚¤ãƒ©ãƒ«å‹•ç”»ã‚’ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
                    viral_videos = []
                    for video in all_videos:
                        if self.detector.is_viral_video(video):
                            viral_info = self.detector.extract_video_info(video)
                            viral_videos.append(viral_info)
                    
                    all_viral_videos.extend(viral_videos)
                    
                    logging.info(f"ğŸ“ˆ ãƒªã‚¯ã‚¨ã‚¹ãƒˆ {request_num + 1}/{max_requests}: "
                               f"{len(all_videos)}ä»¶å‡¦ç†, {len(viral_videos)}ä»¶ãƒã‚¤ãƒ©ãƒ«æ¤œå‡º")
                    
                    # é€²æ—è¡¨ç¤º
                    if viral_videos:
                        for video in viral_videos[:3]:  # æœ€åˆã®3ä»¶ã‚’è¡¨ç¤º
                            logging.info(f"ğŸ”¥ ãƒã‚¤ãƒ©ãƒ«å‹•ç”»: {video['description'][:50]}... "
                                       f"({video['views']:,}å†ç”Ÿ, {video['hours_since_post']}hçµŒé)")
                
                except Exception as e:
                    logging.error(f"ãƒ‡ãƒ¼ã‚¿åé›†ã‚¨ãƒ©ãƒ¼ (ãƒªã‚¯ã‚¨ã‚¹ãƒˆ {request_num + 1}): {e}")
                    continue
        
        # é‡è¤‡é™¤å»
        unique_viral_videos = self._remove_duplicates(all_viral_videos)
        
        logging.info(f"âœ… åé›†å®Œäº†: {total_processed}ä»¶å‡¦ç†, {len(unique_viral_videos)}ä»¶ã®ãƒã‚¤ãƒ©ãƒ«å‹•ç”»ã‚’æ¤œå‡º")
        
        return unique_viral_videos
    
    def _merge_videos(self, fyp_videos: List[Dict], trending_videos: List[Dict]) -> List[Dict]:
        """å‹•ç”»ãƒªã‚¹ãƒˆã‚’ãƒãƒ¼ã‚¸ï¼ˆé‡è¤‡é™¤å»ï¼‰"""
        seen_ids = set()
        merged_videos = []
        
        for video in fyp_videos + trending_videos:
            video_id = video.get('id')
            if video_id and video_id not in seen_ids:
                seen_ids.add(video_id)
                merged_videos.append(video)
        
        return merged_videos
    
    def _remove_duplicates(self, viral_videos: List[Dict]) -> List[Dict]:
        """ãƒã‚¤ãƒ©ãƒ«å‹•ç”»ã®é‡è¤‡é™¤å»"""
        seen_ids = set()
        unique_videos = []
        
        for video in viral_videos:
            video_id = video.get('video_id')
            if video_id and video_id not in seen_ids:
                seen_ids.add(video_id)
                unique_videos.append(video)
        
        return unique_videos
    
    def export_to_csv(self, viral_videos: List[Dict]) -> str:
        """CSVå‡ºåŠ›"""
        timestamp = datetime.now().strftime('%Y%m%d_%H%M%S')
        filename = f"viral_videos_{timestamp}.csv"
        
        try:
            with open(filename, 'w', newline='', encoding='utf-8-sig') as csvfile:
                if not viral_videos:
                    csvfile.write("ãƒ‡ãƒ¼ã‚¿ãªã—\n")
                    return filename
                
                fieldnames = [
                    'å‹•ç”»ID', 'èª¬æ˜', 'å†ç”Ÿæ•°', 'ã„ã„ã­æ•°', 'ã‚³ãƒ¡ãƒ³ãƒˆæ•°', 'ã‚·ã‚§ã‚¢æ•°',
                    'ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå', 'ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°', 'æŠ•ç¨¿æ—¥æ™‚', 'çµŒéæ™‚é–“(h)', 
                    'ãƒã‚¤ãƒ©ãƒ«é€Ÿåº¦', 'å‹•ç”»URL', 'ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°', 'èªè¨¼æ¸ˆã¿'
                ]
                
                writer = csv.DictWriter(csvfile, fieldnames=fieldnames)
                writer.writeheader()
                
                for video in viral_videos:
                    writer.writerow({
                        'å‹•ç”»ID': video['video_id'],
                        'èª¬æ˜': video['description'],
                        'å†ç”Ÿæ•°': video['views'],
                        'ã„ã„ã­æ•°': video['likes'],
                        'ã‚³ãƒ¡ãƒ³ãƒˆæ•°': video['comments'],
                        'ã‚·ã‚§ã‚¢æ•°': video['shares'],
                        'ã‚¢ã‚«ã‚¦ãƒ³ãƒˆå': video['author_username'],
                        'ãƒ•ã‚©ãƒ­ãƒ¯ãƒ¼æ•°': video['author_follower_count'],
                        'æŠ•ç¨¿æ—¥æ™‚': video['create_time'],
                        'çµŒéæ™‚é–“(h)': video['hours_since_post'],
                        'ãƒã‚¤ãƒ©ãƒ«é€Ÿåº¦': video['viral_speed'],
                        'å‹•ç”»URL': video['video_url'],
                        'ãƒãƒƒã‚·ãƒ¥ã‚¿ã‚°': video['hashtags'],
                        'èªè¨¼æ¸ˆã¿': 'âœ“' if video['is_verified'] else ''
                    })
            
            logging.info(f"ğŸ“„ CSVå‡ºåŠ›å®Œäº†: {filename}")
            return filename
            
        except Exception as e:
            logging.error(f"CSVå‡ºåŠ›ã‚¨ãƒ©ãƒ¼: {e}")
            return ""
    
    async def run(self):
        """ãƒ¡ã‚¤ãƒ³å®Ÿè¡Œ"""
        try:
            # ãƒã‚¤ãƒ©ãƒ«å‹•ç”»åé›†
            viral_videos = await self.collect_viral_videos()
            
            if not viral_videos:
                logging.warning("âš ï¸ ãƒã‚¤ãƒ©ãƒ«å‹•ç”»ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“ã§ã—ãŸ")
                return
            
            # çµæœè¡¨ç¤º
            logging.info(f"\nğŸ‰ {len(viral_videos)}ä»¶ã®ãƒã‚¤ãƒ©ãƒ«å‹•ç”»ã‚’æ¤œå‡ºã—ã¾ã—ãŸï¼")
            logging.info("=" * 60)
            
            for i, video in enumerate(viral_videos[:5], 1):  # ä¸Šä½5ä»¶è¡¨ç¤º
                logging.info(f"{i}. {video['description']}")
                logging.info(f"   ğŸ‘€ {video['views']:,}å†ç”Ÿ | â° {video['hours_since_post']}hçµŒé | ğŸš€ {video['viral_speed']:,}/h")
                logging.info(f"   ğŸ”— {video['video_url']}")
                logging.info("")
            
            # CSVå‡ºåŠ›
            if self.config.get('output_csv', True):
                csv_file = self.export_to_csv(viral_videos)
                if csv_file:
                    logging.info(f"ğŸ“„ CSVãƒ•ã‚¡ã‚¤ãƒ«: {csv_file}")
            
            # Google Sheetså‡ºåŠ›
            if GOOGLE_SHEETS_AVAILABLE and self.sheets_exporter.gc:
                spreadsheet_id = self.config.get('spreadsheet_id')
                success = self.sheets_exporter.export_to_sheets(viral_videos, spreadsheet_id)
                if success:
                    logging.info("ğŸ“Š Google Sheetsã«å‡ºåŠ›å®Œäº†")
                else:
                    logging.warning("âš ï¸ Google Sheetså‡ºåŠ›ã«å¤±æ•—ã—ã¾ã—ãŸ")
            
            logging.info("âœ… å‡¦ç†å®Œäº†")
            
        except Exception as e:
            logging.error(f"å®Ÿè¡Œã‚¨ãƒ©ãƒ¼: {e}")
            raise

def main():
    """ãƒ¡ã‚¤ãƒ³é–¢æ•°"""
    import argparse
    import asyncio
    
    parser = argparse.ArgumentParser(description='TikTok Viral Video Detector MVP')
    parser.add_argument('--create-config', action='store_true', help='ã‚µãƒ³ãƒ—ãƒ«è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆ')
    parser.add_argument('--config', default='config.json', help='è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹')
    
    args = parser.parse_args()
    
    if args.create_config:
        mvp = TikTokViralMVP()
        mvp.create_sample_config()
        return
    
    # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒã‚§ãƒƒã‚¯
    if not os.path.exists(args.config):
        print(f"âŒ è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {args.config}")
        print("ğŸ’¡ --create-config ã§ã‚µãƒ³ãƒ—ãƒ«è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’ä½œæˆã—ã¦ãã ã•ã„")
        sys.exit(1)
    
    # MVPå®Ÿè¡Œ
    mvp = TikTokViralMVP(args.config)
    
    # TikAPIã‚­ãƒ¼ãƒã‚§ãƒƒã‚¯
    if mvp.config['tikapi_key'] == 'YOUR_TIKAPI_KEY_HERE':
        print("âŒ TikAPIã‚­ãƒ¼ãŒè¨­å®šã•ã‚Œã¦ã„ã¾ã›ã‚“")
        print("ğŸ“ config.json ã§TikAPIã‚­ãƒ¼ã‚’è¨­å®šã—ã¦ãã ã•ã„")
        sys.exit(1)
    
    # å®Ÿè¡Œ
    try:
        asyncio.run(mvp.run())
    except KeyboardInterrupt:
        print("\nâ¹ï¸ å‡¦ç†ã‚’ä¸­æ–­ã—ã¾ã—ãŸ")
    except Exception as e:
        print(f"âŒ ã‚¨ãƒ©ãƒ¼ãŒç™ºç”Ÿã—ã¾ã—ãŸ: {e}")
        sys.exit(1)

if __name__ == "__main__":
    main()

